{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## UNT MODELS for DARPA Hurdle 3 \n",
    "\n",
    "Given that a Random Guess does not perform well enough to pass the 3rd hurdle of the DARPA Sharing Spectrum Competition, Then a more intelligent solution is required. In this document I propose 3 posible solutions for this 3rd hurdle. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "#### Solution 1: Generic Random Forest Predictor given the past behaviour\n",
    "\n",
    "   This is the fastest and one of the easiest methods I could think of. Given the last outputs of the Player and the DARPA player let a Random Forest predict the next output given a sequence of previous outputs. \n",
    "   \n",
    "   Input sequences may be M-length or Fixed-Length (e.g. 100 samples) \n",
    "     \n",
    "   Output of the estimator is a M-length-1 vector with the probabilities of each posible output. From here we select the most Probable output as our prediction and the Least probable output as out selection \n",
    "   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# import UNT_hurdle3.py  for training and simulation \n",
    "\n",
    "import UNT_hurdle3 as h3 \n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "import time\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.cross_validation import KFold\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "\n",
    "class RFPlayer:\n",
    "    ''' A Simple class that simulate a RandomForest base Player for the #3 Hurdle of the DARPA Competition  '''\n",
    "    import numpy as np\n",
    "    from sklearn.ensemble import RandomForestClassifier                       \n",
    "        \n",
    "        \n",
    "        \n",
    "    def __init__ (self, N,retrain=500, seq_size = 100):\n",
    "        self._type = \"RF\"\n",
    "        self.N = N                        ## Random N-states (NOT USED)\n",
    "        self.M = N                        ##  M-outputs\n",
    "        self.clf = RandomForestClassifier(n_estimators=25) ## Our estimator\n",
    "        self.retrain = retrain            ## Retrain after #retrain turns of the game\n",
    "        self.input_size = seq_size        ## How many lags should we include\n",
    "        self.Dataset = self.createDataset(seq_size)\n",
    "        self.record = pd.DataFrame( columns=['Player_Last','Last','pred'])\n",
    "        self.feature = []\n",
    "        self.turn = 0\n",
    "        self.LastPred = -1\n",
    "                            \n",
    "        \n",
    "        # In order to get A -> choice from Q column\n",
    "    def start(self):\n",
    "\n",
    "        D,P = [np.random.choice(range(1,self.M)),np.random.choice(range(1,self.M))]\n",
    "        self.Prev_D = D\n",
    "        return D,P\n",
    "        \n",
    "    def step(self, A):\n",
    "        \n",
    "        self.turn = self.turn +1\n",
    "        self.appendData(A,self.Prev_D, self.LastPred)\n",
    "        \n",
    "        if self.turn < self.retrain:\n",
    "            D,P = self.start()\n",
    "                    \n",
    "        else:\n",
    "            # check if is time to train \n",
    "            if self.turn%self.retrain == 0:\n",
    "                # Train\n",
    "                self.Train()\n",
    "                    \n",
    "            D,P = self.predict()            \n",
    "                 \n",
    "        self.Prev_D = D\n",
    "        self.LastPred = P\n",
    "        return [D,P]\n",
    "    \n",
    "    \n",
    "    def createDataset(self, lags):\n",
    "        Player_names = ['Player_lag_{0} '.format(s) for s in range(1,lags)]\n",
    "        Bot_names = [\"Bot_lag_{0}\".format(s) for s in range(1,lags)]\n",
    "        cols = np.concatenate([['Player_Last','Last'],Player_names,Bot_names], axis=0)\n",
    "        \n",
    "                                           \n",
    "        df = pd.DataFrame(columns=['Player_Last','Last'], dtype = 'int32')\n",
    "        \n",
    "        return df        \n",
    "    \n",
    "    def FormatData(self):\n",
    "        \n",
    "        tdf = pd.concat([self.record.Player_Last.shift(n) for n in range(1,self.input_size)], axis=1)\n",
    "        tdf.columns = ['Player_lag_{0} '.format(s) for s in range(1,self.input_size)]\n",
    "        ttdf = pd.concat([self.record.Last.shift(n) for n in range(1,self.input_size) ], axis=1)\n",
    "        ttdf.columns = ['Bot_lag_{0} '.format(s) for s in range(1,self.input_size)]\n",
    "\n",
    "        df = pd.concat([self.record,tdf,ttdf], axis=1)\n",
    "        \n",
    "        return df\n",
    "    \n",
    "    def appendData(self, A, D,P):\n",
    "                \n",
    "        self.record = self.record.append(pd.DataFrame([[D,A,P]], columns=['Player_Last','Last','pred']),ignore_index=True)\n",
    "        self.Dataset = self.FormatData()\n",
    "        \n",
    "    def Train(self):                \n",
    "        \n",
    "        print \"Training.. \"\n",
    "        df = self.Dataset.drop('pred',1).copy()\n",
    "        df['Label'] = self.Dataset.Last.shift(-1)  \n",
    "        df = df.dropna(axis=0) # Remove NA rows \n",
    "        rf = RandomForestClassifier(n_estimators=20) # Basic Clf\n",
    "        \n",
    "        #run grid search\n",
    "        kf = KFold(df.shape[0],n_folds=3)\n",
    "        grid_search = GridSearchCV(rf,{})  \n",
    "        \n",
    "        \n",
    "        x = df.drop('Label',1)\n",
    "        y = df.Label\n",
    "        self.clf = grid_search.fit(x,y)            \n",
    "        \n",
    "        #print \"Train ACC:\", accuracy_score(y, self.clf.predict(x))\n",
    "        return True    \n",
    "\n",
    "    \n",
    "    def predict(self):\n",
    "        proba = self.clf.predict_proba(self.Dataset.drop('pred',1)[-1:])\n",
    "        \n",
    "        l = self.Dataset.Last.unique()\n",
    "        l.sort(axis=0)\n",
    "        \n",
    "\n",
    "        \n",
    "        return l[proba.argmin()], l[proba.argmax()] # P = More Likely, D = Less Likely \n",
    "        \n",
    "    def restart(self):\n",
    "        print \"Restarting.. \"\n",
    "        self.__init__(self.N,self.retrain,self.input_size)\n",
    "        return True\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[4, 7]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = RFPlayer(10)\n",
    "test.start()\n",
    "test.step(1)\n",
    "test.step(2)\n",
    "test.step(3)\n",
    "test.step(4)\n",
    "test.step(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training.. \n"
     ]
    }
   ],
   "source": [
    "for i in range(0,100):\n",
    "    test.step(1)\n",
    "    test.step(2)\n",
    "    test.step(3)\n",
    "    test.step(4)\n",
    "    test.step(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#test.clf.predict_proba(test.Dataset[-1:])\n",
    "test.Dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total MC Runs 10\n",
      "Total Turns 30000\n",
      "Restarting.. \n"
     ]
    }
   ],
   "source": [
    "P1 = h3.RandomPlayer(10,10)\n",
    "RFP = RFPlayer(10,retrain=29000)\n",
    "\n",
    "test = h3.Hurdle_MC(P1,RFP,total_turns = 30000)\n",
    "\n",
    "print \"Total MC Runs\", test.mc_runs\n",
    "print \"Total Turns\", test.turns\n",
    "%time test.simulate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test.PlayerA.Dataset[test.PlayerA.Dataset.Player_Last == test.PlayerA.Dataset.Last]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test.PlayerA.Dataset.to_csv('Test_RF.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Solution 2: eXtreme Gradient Bosting Machine (XGB)  given the past behaviour\n",
    "\n",
    "   This is an evolution of the first method, However it requires the instalation of XGB in the docker_container. Same procedure as the Solution 1 \n",
    "   \n",
    "   Input sequences may be M-length or Fixed-Length (e.g. 100 samples) \n",
    "     \n",
    "   Output of the estimator is a M-length-1 vector with the probabilities of each posible output. From here we select the most Probable output as our prediction and the Least probable output as out selection \n",
    "\n",
    "#### Solution 3: Long Short Term Memory Neural Networks on Tensorflow (The good stuff!)  given the past behaviour\n",
    "\n",
    "   This is completly different approach from the previous models. (TODO: Add more info for LSTM if needed) \n",
    "   \n",
    "           \n",
    "   Output of the estimator is a M-length-1 vector with the probabilities of each posible output. From here we select the most Probable output as our prediction and the Least probable output as out selection \n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print test.PlayerA.clf.predict_proba(test.PlayerA.Dataset.drop('pred',1)[-5:])\n",
    "print test.PlayerA.clf.predict(test.PlayerA.Dataset.drop('pred',1)[-5:])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "l = test.PlayerA.Dataset.Last.unique()\n",
    "l.sort(axis=0)\n",
    "print l\n",
    "\n",
    "proba = test.PlayerA.clf.predict_proba(test.PlayerA.Dataset.drop('pred',1)[-1:])\n",
    "pred = test.PlayerA.clf.predict(test.PlayerA.Dataset.drop('pred',1)[-1:])\n",
    "\n",
    "print \"More Likely: \", l[proba.argmax()], \" Pred: \", pred\n",
    "print \"Less Likely: \", l[proba.argmin()], \" Pred: \", pred, \" Probas: \", proba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "proba.argmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
